{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use audio fragment for prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Set the paths to your ffmpeg and ffprobe executables\n",
    "# AudioSegment.ffmpeg = \"/opt/homebrew/bin/ffmpeg\"\n",
    "# AudioSegment.ffprobe = \"/opt/homebrew/bin/ffprobe\"\n",
    "os.environ[\"PATH\"] += f\"{os.pathsep}/opt/homebrew/bin\"\n",
    "\n",
    "# Load the input MP3 file\n",
    "input_file = \"./podcasts/the_home_run/How to prepare yourself to bid at an auction.mp3\"\n",
    "output_file = \"./podcasts/dev.mp3\"\n",
    "audio = AudioSegment.from_mp3(input_file)\n",
    "\n",
    "# Slice the first minute (60,000 milliseconds)\n",
    "first_minute = audio[:60_000]\n",
    "\n",
    "# Export the sliced audio as a new MP3 file\n",
    "first_minute.export(output_file, format=\"mp3\")\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript in list(transcript_dir.rglob(\"*/*.csv\")):\n",
    "    transcript_df = (\n",
    "        parse_transcript(transcript)\n",
    "        .assign(podcast=transcript.parent.name)\n",
    "        .assign(episode=transcript.stem)\n",
    "        # for QA with sources\n",
    "        .assign(\n",
    "            source=lambda x: x.apply(\n",
    "                lambda y: f\"{y.podcast} | {y.episode} | {y.start} | {y.end}\", axis=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # print(f\"Ingesting transcript: {transcript.name}\")\n",
    "    estimate_cost_of_ingest(transcript_df)\n",
    "    ingest_transcript_df_pinecone(transcript_df)\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic question answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingest import llm, vectordb\n",
    "\n",
    "# how many docs in underlying DB\n",
    "vectordb._client._count(\"langchain\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "\n",
    "qa = VectorDBQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", vectorstore=vectordb_pinecone\n",
    ")\n",
    "query = \"Can you give me a strategy for competing at auctions?\"\n",
    "qa.run(query)\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA with source references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=vectordb_pinecone.as_retriever()\n",
    ")\n",
    "res = chain(\n",
    "    {\"question\": \"When is a good time to buy as a first home buyer?\"},\n",
    "    # return_only_outputs=True,\n",
    ")\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question/answer with custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the context below to write a 100 word paragraph response to the question:\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "\n",
    "\n",
    "def question_answer_custom_prompt(question):\n",
    "    docs = vectordb.similarity_search(question, k=10)\n",
    "    inputs = [{\"context\": doc.page_content, \"question\": question} for doc in docs]\n",
    "    return chain.apply(inputs)\n",
    "\n",
    "\n",
    "res = question_answer_custom_prompt(\n",
    "    \"Can you write me a to-do list for first home buyer?\"\n",
    ")\n",
    "res\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical summary of materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Summarize the below context in a bullet-pointed, 100 word technical analysis in response to the question. Be sure to group related bits of content into thematically relevant sections:\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "\n",
    "def question_answer_custom_prompt(question):\n",
    "    docs = vectordb.similarity_search(question, k=10)\n",
    "    return docs\n",
    "    return chain.run(docs)\n",
    "    # inputs = [{\"context\": doc.page_content, \"question\": question} for doc in docs]\n",
    "    # return chain.apply(inputs)\n",
    "\n",
    "\n",
    "res = question_answer_custom_prompt(\n",
    "    \"What are the steps involved in getting finance pre-approval?\"\n",
    ")\n",
    "res\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
